# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
pretrain_path: '/home/data/jmh/retinanet_res101_checkpoint/retinanetresnet101_ascend_v190_coco2017_research_cv_mAP36.72.ckpt'

enable_modelarts: False
data_url: ""
train_url: ""
checkpoint_url: ""
data_path: "./cache/data"
output_path: "./cache/train"
load_path: "./cache/checkpoint_path"
device_target: Ascend
enable_profiling: False
need_modelarts_dataset_unzip: True
modelarts_dataset_unzip_name: "cocodataset"

# ==============================================================================
img_shape: [1056, 1056]
num_retinanet_boxes: 23239 # 67995 / 9 = 7555 [9,9,9,9,9]变为[1,1,1,1,1]这里要同步修改
match_thershold: 0.5
softnms_sigma: 0.5
nms_thershold: 0.5
min_score: 0.05
max_boxes: 100
nms_pre: 1000

# learing rate settings
global_step: 0
lr_init: 0.000001 
lr_end_rate: 0.005 
warmup_epochs1: 2
warmup_epochs2: 5
warmup_epochs3: 23
warmup_epochs4: 60
warmup_epochs5: 160
momentum: 0.9
weight_decay: 0.00015 # 1.5e-4

# network
num_default: [1, 1, 1, 1, 1]  # [9, 9, 9, 9, 9] -> [1, 1, 1, 1, 1]
extras_out_channels: [256, 256, 256, 256, 256]
feature_size: [132, 66, 33, 17, 9]  # [75, 38, 19, 10, 5]
aspect_ratios:
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
- [0.5, 1.0, 2.0]
steps: [8, 16, 32, 64, 128]
anchor_size: [32, 64, 128, 256, 512]
prior_scaling: [0.1, 0.2]
gamma: 2.0
alpha: 0.25

# `mindrecord_dir` and `coco_root` are better to use absolute path.
mindrecord_dir: "/home/data/jmh/SABL_resize/cache/train/MindRecord_COCO" # 改绝对目录 避免bash的时候又跑一遍
coco_root: "/home/data/jmh/coco_dataset"
train_data_type: "train2017"
val_data_type: "val2017"
instances_set: "annotations/instances_{}.json"
coco_classes: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
                     'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
                     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
                     'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
                     'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
                     'kite', 'baseball bat', 'baseball glove', 'skateboard',
                     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
                     'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
                     'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
                     'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
                     'refrigerator', 'book', 'clock', 'vase', 'scissors',
                     'teddy bear', 'hair drier', 'toothbrush']
num_classes: 80
# The annotation.json position of voc validation dataset.
voc_root: ""
# voc original dataset.
voc_dir: ""
# if coco or voc used, `image_dir` and `anno_path` are useless.
image_dir: ""
anno_path: ""
save_checkpoint: True
keep_checkpoint_max: 30
save_checkpoint_path: "./model"
finish_epoch: 0
checkpoint_path: "./cache/train/model/retinanet-400_458.ckpt" # 用来做val的

# train.py retinanet training
only_create_dataset: False
distribute: False
device_id: 0 # device_id必须在[0, device_num - 1]范围内
device_num: 1
lr: 0.1
train_mode: "pynative" # Graph和其它
mode: "sink" # sink改为了not
dataset: "coco"
epoch_size: 500
batch_size: 32
pre_trained: '/home/data/jmh/retinanet_res101_checkpoint/retinanetresnet101_ascend_v190_coco2017_research_cv_mAP36.72.ckpt'
pre_trained_epoch_size: 400 #默认是0
save_checkpoint_epochs: 1
loss_scale: 1 # 1024
filter_weight: False
run_platform: "Ascend"

# export.py retinanet evaluation
file_format: "MINDIR"
# batch_size: 1
file_name: "retinanet"

# postprocess.py retinanet evaluation
result_path: ''
img_path: ''
img_id_file: ''

---
# Config description for each option
only_create_dataset: 'If set it true, only create Mindrecord, default is False.'
distribute: 'Run distribute, default is False.'
device_id: 'Device id, default is 0.'
device_num: 'Use device nums, default is 1.'
lr: 'Learning rate, default is 0.1.'
mode: 'Run sink mode or not, default is sink.'
dataset: 'Dataset, default is coco.'
epoch_size: 'Epoch size, default is 500.'
batch_size: 'Batch size, default is 32.'
pre_trained: 'Pretrained Checkpoint file path.'
pre_trained_epoch_size: 'Pretrained epoch size.'
save_checkpoint_epochs: 'Save checkpoint epochs, default is 1.'
loss_scale: 'Loss scale, default is 1024.'
filter_weight: 'Filter weight parameters, default is False.'
run_platform: 'Run platform, only support Ascend and GPU.'
file_format: 'file format'
file_name: 'output file name.'
result_path: 'result file path.'
img_path: 'image file path.'
img_id_file: 'image id file.'

enable_modelarts: 'Whether training on modelarts, default: False'
data_url: 'Dataset url for obs'
train_url: 'Training output url for obs'
data_path: 'Dataset path for local'

---
run_platform: ['Ascend', 'GPU']
file_format: ["AIR", "MINDIR"]
